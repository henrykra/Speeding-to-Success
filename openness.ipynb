{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "gameid = 2022090800\n",
    "playid = 56\n",
    "frameid = 159\n",
    "\n",
    "routes_df = pd.read_csv('../route_frames.csv')\n",
    "routes_df['dir_clean'] = routes_df['dir'] * -np.pi / 180 + np.pi/2\n",
    "\n",
    "coverage_df = pd.read_csv('../coverage_frames.csv')\n",
    "coverage_df['dir_clean'] = coverage_df['dir'] * -np.pi / 180 + np.pi/2\n",
    "\n",
    "ball_df = pd.read_csv('../ball_locations.csv')\n",
    "ball_df = ball_df[['gameId', 'playId', 'frameId', 'x', 'y']]\n",
    "\n",
    "stacked_df = pd.concat([routes_df, coverage_df])\n",
    "\n",
    "stacked_df = stacked_df.merge(ball_df, how='left', on=['gameId', 'playId', 'frameId'], suffixes=('', '_ball'))\n",
    "\n",
    "\n",
    "stacked_df['dis_to_ball'] = np.sqrt((stacked_df.x - stacked_df.x_ball)**2 + (stacked_df.y - stacked_df.y_ball)**2)\n",
    "\n",
    "testframe = stacked_df[(stacked_df['gameId'] == gameid) & (stacked_df['playId'] == playid) & (stacked_df['frameId'] == frameid)]\n",
    "testplay = stacked_df[(stacked_df['gameId'] == gameid) & (stacked_df['playId'] == playid)]\n",
    "\n",
    "route_runners = pd.read_csv('../route_runners.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 50, 100)\n",
    "\n",
    "plt.ylim(0, 15)\n",
    "def func(x):\n",
    "    return np.minimum(np.repeat(8, len(x)), 2 + np.exp(x/16))\n",
    "\n",
    "plt.plot(x, func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(frame: pd.DataFrame) -> np.ndarray:\n",
    "\n",
    "    mu_array = np.stack([\n",
    "        (.5 *\n",
    "        frame['s'] *\n",
    "        np.cos(frame['dir_clean'])) + frame['x'],\n",
    "        (.5 *\n",
    "        frame['s'] *\n",
    "        np.sin(frame['dir_clean'])) + frame['y']\n",
    "    ], axis=1)\n",
    "    \n",
    "    return mu_array\n",
    "\n",
    "\n",
    "def get_cov_matricies(frame: pd.DataFrame) -> np.ndarray:    \n",
    "    \n",
    "    # player influence hyperparameters\n",
    "    #scaling_fn = lambda x: np.repeat(4, len(x)) # influence radius relation with distance to ball\n",
    "    scaling_fn = lambda x: np.minimum(np.repeat(8, len(x)), 2 + np.exp(x/16))\n",
    "\n",
    "    speed_ratios = (frame['s'].to_numpy() ** 2) / (18 ** 2)\n",
    "\n",
    "    distances = frame['dis_to_ball'].to_numpy()\n",
    "    diagonals = np.stack([\n",
    "                    np.array(\n",
    "                        (scaling_fn(distances) + scaling_fn(distances) * speed_ratios) / 2\n",
    "                    ),\n",
    "                    np.array(\n",
    "                        (scaling_fn(distances) - scaling_fn(distances) * speed_ratios) / 2\n",
    "                    )]\n",
    "                , axis=1)\n",
    "        \n",
    "    scaling_matricies = diagonals[:, None, :] * np.eye(2)\n",
    "\n",
    "    thetas = frame['dir_clean'].to_numpy()\n",
    "    rotation_matricies = np.stack([\n",
    "        np.stack([np.cos(thetas), -np.sin(thetas)], axis=1),\n",
    "        np.stack([np.sin(thetas), np.cos(thetas)], axis=1)\n",
    "    ], axis=1)\n",
    "\n",
    "    covariance_matricies = rotation_matricies @ scaling_matricies @ scaling_matricies @ np.transpose(rotation_matricies, (0,2,1))\n",
    "\n",
    "    return covariance_matricies\n",
    "\n",
    "\n",
    "def get_bboxes(means: np.ndarray, covariances: np.ndarray) -> np.ndarray:\n",
    "    eigvals, eigvecs = np.linalg.eigh(covariances)\n",
    "\n",
    "    major_axes = np.sqrt(eigvals[:, 1])\n",
    "    minor_axes = np.sqrt(eigvals[:, 0])\n",
    "\n",
    "    thetas = np.arctan2(eigvecs[:, 1, 1], eigvecs[:, 0, 1])\n",
    "\n",
    "    t = np.tile(np.linspace(0, 2*np.pi, 100), (means.shape[0], 1))\n",
    "\n",
    "    ellipses_x = np.reshape(major_axes, (means.shape[0],1)) * np.cos(t) \n",
    "    ellipses_y = np.reshape(minor_axes, (means.shape[0],1)) * np.sin(t) \n",
    "    \n",
    "    rotation_matricies = np.stack([\n",
    "        np.stack([np.cos(thetas), -np.sin(thetas)], axis=1),\n",
    "        np.stack([np.sin(thetas), np.cos(thetas)], axis=1)\n",
    "    ], axis=1)\n",
    "    \n",
    "    rotated_ellipses = rotation_matricies @ np.stack([ellipses_x, ellipses_y], axis=1)\n",
    "\n",
    "\n",
    "    ellipse_x_final = rotated_ellipses[:, 0, :] + np.reshape(means[:, 0], (means.shape[0], 1))\n",
    "    ellipse_y_final = rotated_ellipses[:, 1, :] + np.reshape(means[:, 1], (means.shape[0], 1))\n",
    "\n",
    "    bboxes = np.stack([\n",
    "        np.min(ellipse_x_final, axis=1), \n",
    "        np.max(ellipse_x_final, axis=1), \n",
    "        np.min(ellipse_y_final, axis=1), \n",
    "        np.max(ellipse_y_final, axis=1)\n",
    "    ], axis=1)\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "    \n",
    "def filter_defender_bboxes(offense: np.ndarray, defense: np.ndarray):\n",
    "    \n",
    "    # cartesian product of offense and defense bboxes\n",
    "    offense_repeated = np.repeat(offense, defense.shape[0], axis=0)\n",
    "    defense_repeated = np.tile(defense, (offense.shape[0], 1))\n",
    "\n",
    "    arr = ~(\n",
    "        (offense_repeated[:,1] < defense_repeated[:,0]) |\n",
    "        (defense_repeated[:,1] < offense_repeated[:,0]) |\n",
    "        (offense_repeated[:,3] < defense_repeated[:,2]) |\n",
    "        (defense_repeated[:,3] < offense_repeated[:,2])\n",
    "    )\n",
    "    return arr.reshape((offense.shape[0], defense.shape[0]))\n",
    "\n",
    "\n",
    "def check_points_in_offense_ellipses(x: np.ndarray, y: np.ndarray, means: np.ndarray, covariances: np.ndarray):\n",
    "\n",
    "    # would like to have this function work for if means and covariances have an extra dimension\n",
    "    \n",
    "    eigvals, eigvecs = np.linalg.eigh(covariances)\n",
    "\n",
    "    points = np.stack([x, y], axis=1) - means # shift by mean\n",
    "\n",
    "    major_axes_len = np.sqrt(eigvals[:, 1])\n",
    "    minor_axes_len = np.sqrt(eigvals[:, 0])\n",
    "\n",
    "    major_axes_dir = eigvecs[:, :, 1]\n",
    "    minor_axes_dir = eigvecs[:, :, 0]\n",
    "    \n",
    "    transformed_points = np.stack([\n",
    "            np.diag(points @ major_axes_dir.T) / major_axes_len,\n",
    "            np.diag(points @ minor_axes_dir.T) / minor_axes_len\n",
    "        ], axis=1)\n",
    "    \n",
    "    return np.sum(transformed_points ** 2, axis=1) <= 1\n",
    "\n",
    "\n",
    "def check_points_in_defense_ellipses(x: np.ndarray, y: np.ndarray, means: np.ndarray, covariances: np.ndarray, filter_array: np.ndarray):\n",
    "    \n",
    "    # need to check each poitn on each defender\n",
    "    eigvals, eigvecs = np.linalg.eigh(covariances)\n",
    "\n",
    "    # shift each point by each mean\n",
    "    points = np.stack([x, y], axis=1)\n",
    "    filtered_means = (\n",
    "        np.tile(\n",
    "            means, (points.shape[0], 1, 1)\n",
    "        ).T * filter_array.T\n",
    "    ).T\n",
    "\n",
    "    expanded_points = np.transpose(\n",
    "        np.tile(\n",
    "            points, (means.shape[0], 1, 1)\n",
    "        ), (1, 0, 2)\n",
    "    )\n",
    "\n",
    "    filtered_points = (\n",
    "        expanded_points.T * filter_array.T\n",
    "    ).T\n",
    "    \n",
    "    shifted_points = filtered_points - filtered_means\n",
    "\n",
    "    major_axes_len = np.sqrt(eigvals[:, 1])\n",
    "    minor_axes_len = np.sqrt(eigvals[:, 0])\n",
    "\n",
    "    major_axes_dir = eigvecs[:, :, 1]\n",
    "    minor_axes_dir = eigvecs[:, :, 0]\n",
    "\n",
    "    filtered_major_evecs = (\n",
    "        np.transpose(\n",
    "            np.tile(\n",
    "                major_axes_dir, (points.shape[0], 1, 1)\n",
    "            )\n",
    "        ,(2, 1, 0)) * filter_array.T\n",
    "    ).T\n",
    "\n",
    "    filtered_minor_evecs = (\n",
    "        np.transpose(\n",
    "            np.tile(\n",
    "                minor_axes_dir, (points.shape[0], 1, 1)\n",
    "            )\n",
    "        ,(2, 1, 0)) * filter_array.T\n",
    "    ).T\n",
    "    \n",
    "    transformed_points = np.stack([\n",
    "        np.diagonal(\n",
    "            shifted_points @ np.transpose(\n",
    "                filtered_major_evecs, (0, 2, 1)\n",
    "            ), axis1=1, axis2=2\n",
    "        ) / major_axes_len,\n",
    "        np.diagonal(\n",
    "            shifted_points @ np.transpose(\n",
    "                filtered_minor_evecs, (0, 2, 1)\n",
    "            ), axis1=1, axis2=2\n",
    "        ) / minor_axes_len,\n",
    "    ], axis=1)\n",
    "\n",
    "    return np.any((np.sum(transformed_points ** 2, axis=1) <= 1) & filter_array, axis=1)\n",
    "\n",
    "\n",
    "def get_bbox_areas(bboxes):\n",
    "    return (bboxes[:, 1] - bboxes[:, 0]) * (bboxes[:, 3] - bboxes[:, 2]) # xmax - xmin * ymax - ymin\n",
    "\n",
    "\n",
    "\n",
    "def get_openness(frame: pd.DataFrame):\n",
    "    offense = frame[frame['wasRunningRoute'] == 1].copy()\n",
    "    defense = frame[frame['wasRunningRoute'].isna()].copy()\n",
    "\n",
    "    if offense.shape[0] == 0:\n",
    "        return False\n",
    "\n",
    "    # mean and covariance matricies for offense\n",
    "    offense_means = get_mean(offense) # n, 2, 1\n",
    "    offense_covs = get_cov_matricies(offense) # n, 2, 2\n",
    "\n",
    "    # mean and covariance matricies for defense\n",
    "    defense_means = get_mean(defense) \n",
    "    defense_covs = get_cov_matricies(defense)\n",
    "\n",
    "    offense_bboxes = get_bboxes(offense_means, offense_covs)\n",
    "    defense_bboxes = get_bboxes(defense_means, defense_covs)\n",
    "\n",
    "    offense_bbox_areas = get_bbox_areas(offense_bboxes)\n",
    "\n",
    "    # create a search grid for each offense bbox\n",
    "    n = 50\n",
    "    search_spaces = np.array([np.meshgrid(np.linspace(xmin, xmax, n), np.linspace(ymin, ymax, n)) for xmin, xmax, ymin, ymax in offense_bboxes])\n",
    "\n",
    "\n",
    "    filter_arr = filter_defender_bboxes(offense_bboxes, defense_bboxes)\n",
    "\n",
    "\n",
    "    # create counts array for each offensive player initialized at zero\n",
    "    counts = np.zeros(offense.shape[0])\n",
    "\n",
    "    # iterate over indecies for search spaces\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            \n",
    "            x_points = search_spaces[:, 0, i, j]\n",
    "            y_points = search_spaces[:, 1, i, j]\n",
    "\n",
    "            in_offense_ellipses = check_points_in_offense_ellipses(\n",
    "                x_points, y_points, offense_means, offense_covs\n",
    "            )\n",
    "\n",
    "            in_any_defense_ellipses = check_points_in_defense_ellipses(\n",
    "                x_points, y_points, defense_means, defense_covs, filter_arr\n",
    "            )\n",
    "            \n",
    "\n",
    "            counts += (in_offense_ellipses) & (in_any_defense_ellipses)\n",
    "\n",
    "    intersection_areas = offense_bbox_areas * (counts / n ** 2)\n",
    "\n",
    "    return 1 - (intersection_areas / offense_bbox_areas)\n",
    "\n",
    "\n",
    "get_openness(testframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frame(play_df: pd.DataFrame, frame):\n",
    "    frame_df = play_df[play_df['frameId'] == frame]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title('Player Influence Zones')\n",
    "    ax.set_ylim(0, 53.3)\n",
    "    ax.set_xlim(frame_df['x'].min() - 10, frame_df['x'].max() + 10)\n",
    "\n",
    "    means = get_mean(frame_df)\n",
    "    covs = get_cov_matricies(frame_df)\n",
    "    \n",
    "    eigvals, eigvecs = np.linalg.eigh(covs)\n",
    "\n",
    "    major_axes = np.sqrt(eigvals[:, 1])\n",
    "    minor_axes = np.sqrt(eigvals[:, 0])\n",
    "\n",
    "    thetas = np.arctan2(eigvecs[:, 1, 1], eigvecs[:, 0, 1])\n",
    "\n",
    "    t = np.tile(np.linspace(0, 2*np.pi, 100), (means.shape[0], 1))\n",
    "\n",
    "    ellipses_x = np.reshape(major_axes, (means.shape[0], 1)) * np.cos(t) \n",
    "    ellipses_y = np.reshape(minor_axes, (means.shape[0], 1)) * np.sin(t) \n",
    "    \n",
    "    rotation_matricies = np.stack([\n",
    "        np.stack([np.cos(thetas), -np.sin(thetas)], axis=1),\n",
    "        np.stack([np.sin(thetas), np.cos(thetas)], axis=1)\n",
    "    ], axis=1)\n",
    "    \n",
    "    rotated_ellipses = rotation_matricies @ np.stack([ellipses_x, ellipses_y], axis=1)\n",
    "\n",
    "\n",
    "    ellipse_x_final = rotated_ellipses[:, 0, :] + np.reshape(means[:, 0], (means.shape[0], 1))\n",
    "    ellipse_y_final = rotated_ellipses[:, 1, :] + np.reshape(means[:, 1], (means.shape[0], 1))\n",
    "\n",
    "    colors = ['blue', 'red']\n",
    "\n",
    "\n",
    "    for i, (ellipse_x, ellipse_y) in enumerate(zip(ellipse_x_final, ellipse_y_final)):\n",
    "        ax.plot(ellipse_x, ellipse_y, color=colors[pd.isna(frame_df.iloc[i].wasRunningRoute)])\n",
    "        ax.scatter(frame_df.iloc[i].x, frame_df.iloc[i].y, color=colors[pd.isna(frame_df.iloc[i].wasRunningRoute)], marker='x')\n",
    "        ax.arrow(frame_df.iloc[i].x, frame_df.iloc[i].y, means[i, 0] - frame_df.iloc[i].x, means[i, 1] - frame_df.iloc[i].y, head_width = .5, head_length=.2, color='black')\n",
    "\n",
    "\n",
    "    return \n",
    "\n",
    "frameids = sorted(testplay.frameId.unique())\n",
    "\n",
    "\n",
    "plot_frame(testplay, frameid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = (\n",
    "    testplay\n",
    "    .merge(route_frame_cutoffs.reset_index(), how='left', on='routeRan')\n",
    "    .merge(start_frames, how='left', on=['gameId', 'playId'])\n",
    ")\n",
    "\n",
    "temp['valid'] = (temp['frameId'] - temp['start_frame'] >= temp['low_perc']) & (temp['frameId'] - temp['start_frame'] <= temp['high_perc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_df.playId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playid = 122\n",
    "testplay = stacked_df[(stacked_df['gameId'] == gameid) & (stacked_df['playId'] == playid)]\n",
    "testplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def animate_play(play_df: pd.DataFrame):\n",
    "    frameid_list = sorted(play_df['frameId'].unique())\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, figsize=(6,8))\n",
    "    axes[0].set_xlabel('X')\n",
    "    axes[0].set_ylabel('Y')\n",
    "    axes[0].set_title('Player Influence Zones')\n",
    "    axes[0].set_ylim(0, 53.3)\n",
    "    axes[0].set_xlim()\n",
    "\n",
    "    axes[1].set_xlabel('Frame')\n",
    "    axes[1].set_ylabel('Openness')\n",
    "    axes[1].set_ylim((.5, 1.01))\n",
    "\n",
    "    first_frame = play_df[play_df['frameId'] == frameid_list[0]]\n",
    "\n",
    "    colors = ['blue', 'red']\n",
    "    open_arrs = {row.nflId: [] for _, row in first_frame[first_frame['wasRunningRoute'] == 1].iterrows()}\n",
    "\n",
    "    def update(frame):\n",
    "        frame_df = play_df[play_df['frameId'] == frameid_list[frame]]\n",
    "\n",
    "        axes[0].clear()\n",
    "        axes[0].set_xlim(frame_df['x'].min() - 10, frame_df['x'].max() + 10)\n",
    "\n",
    "        means = get_mean(frame_df)\n",
    "        covs = get_cov_matricies(frame_df)\n",
    "        \n",
    "        eigvals, eigvecs = np.linalg.eigh(covs)\n",
    "\n",
    "        major_axes = np.sqrt(eigvals[:, 1])\n",
    "        minor_axes = np.sqrt(eigvals[:, 0])\n",
    "\n",
    "        thetas = np.arctan2(eigvecs[:, 1, 1], eigvecs[:, 0, 1])\n",
    "\n",
    "        t = np.tile(np.linspace(0, 2*np.pi, 100), (means.shape[0], 1))\n",
    "\n",
    "        ellipses_x = np.reshape(major_axes, (means.shape[0], 1)) * np.cos(t) \n",
    "        ellipses_y = np.reshape(minor_axes, (means.shape[0], 1)) * np.sin(t) \n",
    "        \n",
    "        rotation_matricies = np.stack([\n",
    "            np.stack([np.cos(thetas), -np.sin(thetas)], axis=1),\n",
    "            np.stack([np.sin(thetas), np.cos(thetas)], axis=1)\n",
    "        ], axis=1)\n",
    "        \n",
    "        rotated_ellipses = rotation_matricies @ np.stack([ellipses_x, ellipses_y], axis=1)\n",
    "\n",
    "\n",
    "        ellipse_x_final = rotated_ellipses[:, 0, :] + np.reshape(means[:, 0], (means.shape[0], 1))\n",
    "        ellipse_y_final = rotated_ellipses[:, 1, :] + np.reshape(means[:, 1], (means.shape[0], 1))\n",
    "\n",
    "\n",
    "\n",
    "        for i, (ellipse_x, ellipse_y) in enumerate(zip(ellipse_x_final, ellipse_y_final)):\n",
    "            axes[0].plot(ellipse_x, ellipse_y, color=colors[pd.isna(frame_df.iloc[i].wasRunningRoute)])\n",
    "            axes[0].scatter(frame_df.iloc[i].x, frame_df.iloc[i].y, color=colors[pd.isna(frame_df.iloc[i].wasRunningRoute)], marker='x')\n",
    "            axes[0].arrow(frame_df.iloc[i].x, frame_df.iloc[i].y, means[i, 0] - frame_df.iloc[i].x, means[i, 1] - frame_df.iloc[i].y, head_width = .5, head_length=.2, color='black')\n",
    "\n",
    "        open_arr = get_openness(frame_df)\n",
    "        print(open_arr)\n",
    "\n",
    "        offense = frame_df.loc[frame_df['wasRunningRoute'] == 1].copy()\n",
    "\n",
    "        if not np.array(open_arr).any():\n",
    "            return\n",
    "        \n",
    "        for id, open in open_arr:\n",
    "            open_arrs[id] += [open]\n",
    "\n",
    "            newcolors = ['grey', 'blue']\n",
    "            \n",
    "            axes[1].plot(range(len(open_arrs[id])), open_arrs[id], color='blue')\n",
    "\n",
    "        \n",
    "\n",
    "        return \n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, update, frames=len(frameid_list), interval=150)\n",
    "    anim.save('anim.gif')\n",
    "    return \n",
    "\n",
    "\n",
    "animate_play(testplay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "# Display a GIF file\n",
    "display(Image(filename=\"anim.gif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(frame: pd.DataFrame) -> np.ndarray:\n",
    "\n",
    "    mu_array = np.stack([\n",
    "        (.5 *\n",
    "        frame['s'] *\n",
    "        np.cos(frame['dir_clean'])) + frame['x'],\n",
    "        (.5 *\n",
    "        frame['s'] *\n",
    "        np.sin(frame['dir_clean'])) + frame['y']\n",
    "    ], axis=1)\n",
    "    \n",
    "    return mu_array\n",
    "\n",
    "\n",
    "def get_cov_matricies(frame: pd.DataFrame) -> np.ndarray:    \n",
    "    \n",
    "    # player influence hyperparameters\n",
    "    scaling_fn = lambda x: np.minimum(np.repeat(8, len(x)), 2 + np.exp(x/16)) # influence radius relation with distance to ball\n",
    "\n",
    "    speed_ratios = (frame['s'].to_numpy() ** 2) / (18 ** 2)\n",
    "\n",
    "    distances = frame['dis_to_ball'].to_numpy()\n",
    "    diagonals = np.stack([\n",
    "                    np.array(\n",
    "                        (scaling_fn(distances) + scaling_fn(distances) * speed_ratios) / 2\n",
    "                    ),\n",
    "                    np.array(\n",
    "                        (scaling_fn(distances) - scaling_fn(distances) * speed_ratios) / 2\n",
    "                    )]\n",
    "                , axis=1)\n",
    "        \n",
    "    scaling_matricies = diagonals[:, None, :] * np.eye(2)\n",
    "\n",
    "    thetas = frame['dir_clean'].to_numpy()\n",
    "    rotation_matricies = np.stack([\n",
    "        np.stack([np.cos(thetas), -np.sin(thetas)], axis=1),\n",
    "        np.stack([np.sin(thetas), np.cos(thetas)], axis=1)\n",
    "    ], axis=1)\n",
    "\n",
    "    covariance_matricies = rotation_matricies @ scaling_matricies @ scaling_matricies @ np.transpose(rotation_matricies, (0,2,1))\n",
    "\n",
    "    return covariance_matricies\n",
    "\n",
    "\n",
    "def get_bboxes(means: np.ndarray, covariances: np.ndarray) -> np.ndarray:\n",
    "    eigvals, eigvecs = np.linalg.eigh(covariances)\n",
    "\n",
    "    major_axes = np.sqrt(eigvals[:, 1])\n",
    "    minor_axes = np.sqrt(eigvals[:, 0])\n",
    "\n",
    "    thetas = np.arctan2(eigvecs[:, 1, 1], eigvecs[:, 0, 1])\n",
    "\n",
    "    t = np.tile(np.linspace(0, 2*np.pi, 100), (means.shape[0], 1))\n",
    "\n",
    "    ellipses_x = np.reshape(major_axes, (means.shape[0],1)) * np.cos(t) \n",
    "    ellipses_y = np.reshape(minor_axes, (means.shape[0],1)) * np.sin(t) \n",
    "    \n",
    "    rotation_matricies = np.stack([\n",
    "        np.stack([np.cos(thetas), -np.sin(thetas)], axis=1),\n",
    "        np.stack([np.sin(thetas), np.cos(thetas)], axis=1)\n",
    "    ], axis=1)\n",
    "    \n",
    "    rotated_ellipses = rotation_matricies @ np.stack([ellipses_x, ellipses_y], axis=1)\n",
    "\n",
    "\n",
    "    ellipse_x_final = rotated_ellipses[:, 0, :] + np.reshape(means[:, 0], (means.shape[0], 1))\n",
    "    ellipse_y_final = rotated_ellipses[:, 1, :] + np.reshape(means[:, 1], (means.shape[0], 1))\n",
    "\n",
    "    bboxes = np.stack([\n",
    "        np.min(ellipse_x_final, axis=1), \n",
    "        np.max(ellipse_x_final, axis=1), \n",
    "        np.min(ellipse_y_final, axis=1), \n",
    "        np.max(ellipse_y_final, axis=1)\n",
    "    ], axis=1)\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "    \n",
    "def filter_defender_bboxes(offense: np.ndarray, defense: np.ndarray):\n",
    "    \n",
    "    # cartesian product of offense and defense bboxes\n",
    "    offense_repeated = np.repeat(offense, defense.shape[0], axis=0)\n",
    "    defense_repeated = np.tile(defense, (offense.shape[0], 1))\n",
    "\n",
    "    arr = ~(\n",
    "        (offense_repeated[:,1] < defense_repeated[:,0]) |\n",
    "        (defense_repeated[:,1] < offense_repeated[:,0]) |\n",
    "        (offense_repeated[:,3] < defense_repeated[:,2]) |\n",
    "        (defense_repeated[:,3] < offense_repeated[:,2])\n",
    "    )\n",
    "    return arr.reshape((offense.shape[0], defense.shape[0]))\n",
    "\n",
    "\n",
    "def check_points_in_offense_ellipses(x: np.ndarray, y: np.ndarray, means: np.ndarray, covariances: np.ndarray):\n",
    "\n",
    "    # would like to have this function work for if means and covariances have an extra dimension\n",
    "    \n",
    "    eigvals, eigvecs = np.linalg.eigh(covariances)\n",
    "\n",
    "    points = np.stack([x, y], axis=1) - means # shift by mean\n",
    "\n",
    "    major_axes_len = np.sqrt(eigvals[:, 1])\n",
    "    minor_axes_len = np.sqrt(eigvals[:, 0])\n",
    "\n",
    "    major_axes_dir = eigvecs[:, :, 1]\n",
    "    minor_axes_dir = eigvecs[:, :, 0]\n",
    "    \n",
    "    transformed_points = np.stack([\n",
    "            np.diag(points @ major_axes_dir.T) / major_axes_len,\n",
    "            np.diag(points @ minor_axes_dir.T) / minor_axes_len\n",
    "        ], axis=1)\n",
    "    \n",
    "    return np.sum(transformed_points ** 2, axis=1) <= 1\n",
    "\n",
    "\n",
    "def check_points_in_defense_ellipses(x: np.ndarray, y: np.ndarray, means: np.ndarray, covariances: np.ndarray, filter_array: np.ndarray):\n",
    "    \n",
    "    # need to check each poitn on each defender\n",
    "    eigvals, eigvecs = np.linalg.eigh(covariances)\n",
    "\n",
    "    # shift each point by each mean\n",
    "    points = np.stack([x, y], axis=1)\n",
    "    filtered_means = (\n",
    "        np.tile(\n",
    "            means, (points.shape[0], 1, 1)\n",
    "        ).T * filter_array.T\n",
    "    ).T\n",
    "\n",
    "    expanded_points = np.transpose(\n",
    "        np.tile(\n",
    "            points, (means.shape[0], 1, 1)\n",
    "        ), (1, 0, 2)\n",
    "    )\n",
    "\n",
    "    filtered_points = (\n",
    "        expanded_points.T * filter_array.T\n",
    "    ).T\n",
    "    \n",
    "    shifted_points = filtered_points - filtered_means\n",
    "\n",
    "    major_axes_len = np.sqrt(eigvals[:, 1])\n",
    "    minor_axes_len = np.sqrt(eigvals[:, 0])\n",
    "\n",
    "    major_axes_dir = eigvecs[:, :, 1]\n",
    "    minor_axes_dir = eigvecs[:, :, 0]\n",
    "\n",
    "    filtered_major_evecs = (\n",
    "        np.transpose(\n",
    "            np.tile(\n",
    "                major_axes_dir, (points.shape[0], 1, 1)\n",
    "            )\n",
    "        ,(2, 1, 0)) * filter_array.T\n",
    "    ).T\n",
    "\n",
    "    filtered_minor_evecs = (\n",
    "        np.transpose(\n",
    "            np.tile(\n",
    "                minor_axes_dir, (points.shape[0], 1, 1)\n",
    "            )\n",
    "        ,(2, 1, 0)) * filter_array.T\n",
    "    ).T\n",
    "    \n",
    "    transformed_points = np.stack([\n",
    "        np.diagonal(\n",
    "            shifted_points @ np.transpose(\n",
    "                filtered_major_evecs, (0, 2, 1)\n",
    "            ), axis1=1, axis2=2\n",
    "        ) / major_axes_len,\n",
    "        np.diagonal(\n",
    "            shifted_points @ np.transpose(\n",
    "                filtered_minor_evecs, (0, 2, 1)\n",
    "            ), axis1=1, axis2=2\n",
    "        ) / minor_axes_len,\n",
    "    ], axis=1)\n",
    "\n",
    "    return np.any((np.sum(transformed_points ** 2, axis=1) <= 1) & filter_array, axis=1)\n",
    "\n",
    "\n",
    "def get_bbox_areas(bboxes):\n",
    "    return (bboxes[:, 1] - bboxes[:, 0]) * (bboxes[:, 3] - bboxes[:, 2]) # xmax - xmin * ymax - ymin\n",
    "\n",
    "\n",
    "\n",
    "def get_openness(frame: pd.DataFrame):\n",
    "    offense = frame[frame['wasRunningRoute'] == 1] # wasRunningRoute == 1\n",
    "    defense = frame[frame['wasRunningRoute'] != 1] # wasRunningRoute == NA\n",
    "\n",
    "    if offense.shape[0] == 0 or offense['frame_clean'].max() < 5:\n",
    "        return []\n",
    "        # return nas if no offense\n",
    "\n",
    "    # get offense nflIds\n",
    "    offense_ids = offense['nflId']\n",
    "\n",
    "\n",
    "    # mean and covariance matricies for offense\n",
    "    offense_means = get_mean(offense) # n, 2, 1\n",
    "    offense_covs = get_cov_matricies(offense) # n, 2, 2\n",
    "\n",
    "    # mean and covariance matricies for defense\n",
    "    defense_means = get_mean(defense) \n",
    "    defense_covs = get_cov_matricies(defense)\n",
    "\n",
    "    offense_bboxes = get_bboxes(offense_means, offense_covs)\n",
    "    defense_bboxes = get_bboxes(defense_means, defense_covs)\n",
    "\n",
    "    offense_bbox_areas = get_bbox_areas(offense_bboxes)\n",
    "\n",
    "    # create a search grid for each offense bbox\n",
    "    n = 50\n",
    "    search_spaces = np.array([np.meshgrid(np.linspace(xmin, xmax, n), np.linspace(ymin, ymax, n)) for xmin, xmax, ymin, ymax in offense_bboxes])\n",
    "\n",
    "    filter_arr = filter_defender_bboxes(offense_bboxes, defense_bboxes)\n",
    "\n",
    "\n",
    "    # create counts array for each offensive player initialized at zero\n",
    "    counts = np.zeros(offense.shape[0])\n",
    "\n",
    "    # iterate over indecies for search spaces\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            \n",
    "            x_points = search_spaces[:, 0, i, j]\n",
    "            y_points = search_spaces[:, 1, i, j]\n",
    "\n",
    "            in_offense_ellipses = check_points_in_offense_ellipses(\n",
    "                x_points, y_points, offense_means, offense_covs\n",
    "            )\n",
    "\n",
    "            in_any_defense_ellipses = check_points_in_defense_ellipses(\n",
    "                x_points, y_points, defense_means, defense_covs, filter_arr\n",
    "            )\n",
    "            \n",
    "\n",
    "            counts += (in_offense_ellipses) & (in_any_defense_ellipses)\n",
    "\n",
    "    intersection_areas = offense_bbox_areas * (counts / n ** 2)\n",
    "\n",
    "    offense_opennesses = 1 - (intersection_areas / offense_bbox_areas)\n",
    "    return list(zip(offense_ids, offense_opennesses))\n",
    "\n",
    "    offense_bools = frame['wasRunningRoute'] == 1\n",
    "    result = np.repeat(np.NaN, frame.shape[0])\n",
    "    result[offense_bools] = offense_opennesses\n",
    "    \n",
    "    return result\n",
    "\n",
    "#get_openness(testframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "testplay['frame_clean'] = (\n",
    "    testplay\n",
    "    .loc[testplay['wasTargettedReceiver'] == 1]\n",
    "    .groupby(['gameId', 'playId', 'nflId'])\n",
    "    ['frameId']\n",
    "    .transform(lambda x: x - x.min())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_df['frame_clean'] = (\n",
    "    stacked_df\n",
    "    .loc[stacked_df['wasTargettedReceiver'] == 1]\n",
    "    .groupby(['gameId', 'playId', 'nflId'])\n",
    "    ['frameId']\n",
    "    .transform(lambda x: x - x.min())\n",
    ")\n",
    "\n",
    "targetted_df = stacked_df.loc[stacked_df['wasTargettedReceiver'] == 1].copy()\n",
    "\n",
    "\n",
    "targetted_df['had_forward_pass'] = (\n",
    "    targetted_df\n",
    "    .groupby(['gameId', 'playId', 'nflId'])\n",
    "    ['event']\n",
    "    .transform(lambda x: 'pass_forward' in x.to_list())\n",
    ")\n",
    "\n",
    "def low_perc(x):\n",
    "    return np.percentile(x, 10)\n",
    "\n",
    "def high_perc(x):\n",
    "    return np.percentile(x, 90)\n",
    "\n",
    "route_frame_cutoffs = (\n",
    "    targetted_df.loc[(targetted_df['had_forward_pass']) & (targetted_df['event'] == 'pass_forward')]\n",
    "    .groupby('routeRan')\n",
    "    ['frame_clean']\n",
    "    .agg([low_perc, 'mean', high_perc])\n",
    "    #.rename(columns={'low_perc': '5th Percentile', 'high_perc': '95th Percentile'})\n",
    ")\n",
    "\n",
    "route_frame_cutoffs.reset_index()\n",
    "print(route_frame_cutoffs.reset_index().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should take about 9hr\n",
    "result = (\n",
    "    stacked_df\n",
    "    .groupby(['gameId', 'playId', 'frameId'])\n",
    "    #[col_list]\n",
    "    .apply(get_openness)\n",
    ")\n",
    "open_df = result.explode().reset_index()\n",
    "open_df['nflId'] = open_df[0].str[0]\n",
    "open_df['openness'] = open_df[0].str[1]\n",
    "open_df.drop(columns=0) # final time 69 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = stacked_df.groupby(['gameId', 'playId', 'nflId'])['routeRan'].first().reset_index()\n",
    "route_frame_cutoffs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_frames = (\n",
    "    stacked_df\n",
    "    .groupby(['gameId', 'playId'])\n",
    "    ['frameId']\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(columns={'frameId': 'start_frame'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_df_with_routes = (\n",
    "    open_df\n",
    "    .loc[open_df['nflId'].notna()]\n",
    "    .merge(routes, how='left', on=['gameId', 'playId', 'nflId'])\n",
    "    .merge(route_frame_cutoffs.reset_index(), how='left', on='routeRan')\n",
    "    .merge(start_frames, how='left', on=['gameId', 'playId'])\n",
    ")\n",
    "\n",
    "filtered_open_df = (\n",
    "    open_df_with_routes\n",
    "    .loc[\n",
    "        ((open_df_with_routes['frameId'] - open_df_with_routes['start_frame']) >= open_df_with_routes['low_perc']) & \n",
    "        ((open_df_with_routes['frameId'] - open_df_with_routes['start_frame']) <= open_df_with_routes['high_perc'])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_aggregated_df = filtered_open_df.groupby(['gameId', 'playId', 'nflId'])['openness'].agg('mean').reset_index()\n",
    "play_aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_aggregated_df = play_aggregated_df.groupby('nflId')['openness'].agg(['mean', 'count'])\n",
    "player_aggregated_df.reset_index().sort_values(['mean', 'count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_aggregated_df.to_csv('9_week_play_aggregated.csv')\n",
    "player_aggregated_df.to_csv('9_week_player_aggregated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = pd.read_csv('../data/filtered_combine.csv')\n",
    "play_aggregated_df.merge(combine, left_on='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = player_aggregated_df.loc[player_aggregated_df['count'] >= 200, ['mean', 'count']].reset_index().sort_values(['mean', 'count'], ascending=False).merge(pd.read_csv('../route_runners.csv'), how='left', on='nflId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    play_aggregated_df\n",
    "    .merge(routes, how='left', on=['gameId', 'playId', 'nflId'])\n",
    "    .groupby(['nflId', 'routeRan'])\n",
    "    ['openness']\n",
    "    .agg(['mean', 'count'])\n",
    "    .reset_index()\n",
    "    .sort_values(['mean', 'count'], ascending=False)\n",
    "    .merge(route_runners, how='left', on='nflId')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[t['position'] == 'WR'].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_nfl_field(ax):\n",
    "    field_length = 40\n",
    "    field_width = 20\n",
    "    hash_dist = field_width / 2  # Hash marks closer to the center\n",
    "    yard_line_spacing = 10  # Every 5 yards\n",
    "\n",
    "    # Set background color with transparency\n",
    "    ax.set_facecolor((0.0, 0.5, 0.0, 0.6))  # RGBA (Green with transparency)\n",
    "\n",
    "    # Draw outer boundary\n",
    "    ax.plot([0, 0, field_length, field_length, 0], \n",
    "            [0, field_width, field_width, 0, 0], \n",
    "            'black', linewidth=2)\n",
    "\n",
    "    # Draw yard lines\n",
    "    for yd in range(0, field_length + 1, yard_line_spacing):\n",
    "        ax.plot([yd, yd], [0, field_width], 'gray', linestyle=\"--\", linewidth=0.8)\n",
    "\n",
    "    # Draw hash marks (closer to center)\n",
    "    for yd in range(1, field_length):  # Exclude goal lines\n",
    "        for y in [field_width / 2 - hash_dist / 2, field_width / 2 + hash_dist / 2]:  \n",
    "            ax.plot([yd, yd], [y - 0.3, y + 0.3], 'black', linewidth=1)\n",
    "\n",
    "    # Draw midfield 50-yard line\n",
    "    #ax.plot([50, 50], [0, field_width], 'black', linewidth=2)\n",
    "\n",
    "    # Remove axes\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim(0, field_length)\n",
    "    ax.set_ylim(0, field_width)\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "# Create figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "# Draw two NFL fields\n",
    "for ax in axes:\n",
    "    draw_nfl_field(ax)\n",
    "\n",
    "\n",
    "x = [18.5, 20]\n",
    "y = [11, 10]\n",
    "s = [12, 4]\n",
    "dir = [155/180 * np.pi, 75/180 * np.pi]\n",
    "ball = [35, 25]\n",
    "teams = ['offense', 'defense']\n",
    "colors = ['blue', 'red']\n",
    "\n",
    "axes[0].scatter(x[0], y[0], color=colors[0], label=teams[0])\n",
    "axes[0].scatter(x[1], y[1], color=colors[1], label=teams[1])\n",
    "axes[0].set_title('Low Euclidean Distance')\n",
    "axes[0].legend()\n",
    "\n",
    "\n",
    "x = [20, 12]\n",
    "y = [10, 10]\n",
    "dir = [75/180 * np.pi, 155/180 * np.pi]\n",
    "ball = [35, 25]\n",
    "\n",
    "axes[1].scatter(x[0], y[0], color=colors[0], label=teams[0])\n",
    "axes[1].scatter(x[1], y[1], color=colors[1], label=teams[1])\n",
    "axes[1].set_title('High Euclidean Distance')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def get_cov_matrix(s, d, theta):\n",
    "    \n",
    "    scaling_fn = lambda x: min(8, 2 + np.exp(x/16))\n",
    "    speed_ratio = s**2 / 18**2 # speed ratio (18 is max speed)\n",
    "\n",
    "    scaling_matrix = np.array([\n",
    "        [(scaling_fn(d) + (scaling_fn(d) * speed_ratio)) / 2, 0],\n",
    "        [0, (scaling_fn(d) - (scaling_fn(d) * speed_ratio)) / 2]    \n",
    "    ])\n",
    "    rotation_matrix = np.array([\n",
    "        [np.cos(theta), -np.sin(theta)], \n",
    "        [np.sin(theta), np.cos(theta)]\n",
    "    ])\n",
    "\n",
    "    covariance_matrix = rotation_matrix @ scaling_matrix @ scaling_matrix @ np.linalg.inv(rotation_matrix)\n",
    "\n",
    "    return covariance_matrix\n",
    "\n",
    "\n",
    "def get_mean(xi, yi, s, theta):\n",
    "    mu = np.array([xi, yi]) + np.array([s * np.cos(theta), s * np.sin(theta)]) * .5\n",
    "    return mu\n",
    "\n",
    "def plot_sample(x_, y_, s_, dir_, ball_, team_, color_, ax):\n",
    "    for i in range(2):\n",
    "        x = x_[i]\n",
    "        y = y_[i]\n",
    "        s = s_[i]\n",
    "        \n",
    "        \n",
    "        team = team_[i]\n",
    "        color = color_[i]\n",
    "        dis_to_ball = np.sqrt((ball_[0] - x) ** 2 - (ball_[1] - y) ** 2)\n",
    "        theta = dir_[i]\n",
    "\n",
    "        # Given mean and covariance\n",
    "        mu = get_mean(x, y, s, theta)# Mean vector\n",
    "        Sigma = get_cov_matrix(s, dis_to_ball, theta)  # Covariance matrix\n",
    "\n",
    "        # Given PDF value\n",
    "        for n in [.1, .2, .4, .8, 1.6]:\n",
    "\n",
    "            # Compute determinant and inverse of Sigma\n",
    "            det_Sigma = np.linalg.det(Sigma)\n",
    "\n",
    "            # Eigen decomposition of covariance matrix\n",
    "            eigvals, eigvecs = np.linalg.eigh(Sigma)\n",
    "\n",
    "            # Compute semi-axis lengths\n",
    "            a = n * np.sqrt(eigvals[1])  # Major axis\n",
    "            b = n * np.sqrt(eigvals[0])  # Minor axis\n",
    "\n",
    "            # Compute rotation angle\n",
    "            theta = np.arctan2(eigvecs[1, 1], eigvecs[0, 1])\n",
    "\n",
    "            # Generate ellipse points\n",
    "            t = np.linspace(0, 2 * np.pi, 100)\n",
    "            ellipse_x = a * np.cos(t)\n",
    "            ellipse_y = b * np.sin(t)\n",
    "\n",
    "            # Rotate the ellipse\n",
    "            R = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                        [np.sin(theta), np.cos(theta)]])\n",
    "            rotated_ellipse = R @ np.array([ellipse_x, ellipse_y])\n",
    "\n",
    "            # Shift ellipse to the mean\n",
    "            ellipse_x_final = rotated_ellipse[0, :] + mu[0]\n",
    "            ellipse_y_final = rotated_ellipse[1, :] + mu[1]\n",
    "\n",
    "            ax.plot(ellipse_x_final, ellipse_y_final, color, lw=.7)\n",
    "\n",
    "\n",
    "        ax.scatter(x, y, color=color, label=team)\n",
    "        ax.arrow(x, y, mu[0] - x, mu[1] - y, head_width = 1, head_length=.8, color='black', zorder=5)\n",
    "\n",
    "        ax.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "# Draw two NFL fields\n",
    "for ax in axes:\n",
    "    draw_nfl_field(ax)\n",
    "\n",
    "\n",
    "x = [18.5, 20]\n",
    "y = [11, 10]\n",
    "s = [12, 4]\n",
    "dir = [155/180 * np.pi, 75/180 * np.pi]\n",
    "ball = [35, 25]\n",
    "teams = ['offense', 'defense']\n",
    "colors = ['blue', 'red']\n",
    "\n",
    "\n",
    "plot_sample(x, y, s, dir, ball, teams, colors, axes[0])\n",
    "axes[0].set_title('Low Influence Overlap')\n",
    "\n",
    "x = [20, 12]\n",
    "y = [10, 10]\n",
    "s = [12, 4]\n",
    "dir = [np.pi, 0]\n",
    "ball = [25, 10]\n",
    "\n",
    "plot_sample(x, y, s, dir, ball, teams, colors, axes[1])\n",
    "axes[1].set_title('High Influence Overlap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "# Draw two NFL fields\n",
    "for ax in axes:\n",
    "    draw_nfl_field(ax)\n",
    "\n",
    "\n",
    "x = [18.5, 20]\n",
    "y = [11, 10]\n",
    "s = [5, 15]\n",
    "dir = [155/180 * np.pi, 75/180 * np.pi]\n",
    "ball = [35, 25]\n",
    "teams = ['offense', 'defense']\n",
    "colors = ['blue', 'red']\n",
    "\n",
    "axes[0].scatter(x[0], y[0], color='red', label='defense')\n",
    "axes[0].scatter(x[1], y[1], color='blue', label='offense')\n",
    "axes[0].set_title('Low Euclidean Distance')\n",
    "axes[0].legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
